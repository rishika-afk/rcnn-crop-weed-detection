{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qoRdg6j5VZsM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzWW-bE3V3-R"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MhxjlEvVZsu"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Land_Assessment/agri_data/data/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVSMq0oFVZsv"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R5EGfaNhVZs2"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Land_Assessment/agri_data/agri_label.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14OzFyhuVZs4"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ5a3UxrVZs-"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T68Bpw5eVZs_"
      },
      "source": [
        "now checking all labeled images are available in the folder or not"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2Yj0y9qVZs_"
      },
      "outputs": [],
      "source": [
        "\n",
        "folder_images = os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi3-c5GQVZtA"
      },
      "outputs": [],
      "source": [
        "len(folder_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jupMEuxyVZtB"
      },
      "outputs": [],
      "source": [
        "train_images = folder_images[:1200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKP1JphFVZtC"
      },
      "outputs": [],
      "source": [
        "test_images = folder_images[1200:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLuwTvsGVZtD"
      },
      "outputs": [],
      "source": [
        "j=0\n",
        "for i in tqdm(list(df['filename'].unique())):\n",
        "    if i in folder_images:\n",
        "        j+=1\n",
        "\n",
        "print(j)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYqb9yEFVZtG"
      },
      "source": [
        "# Visualizing the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KgG6tD2VZtI"
      },
      "outputs": [],
      "source": [
        " _ , axes = plt.subplots(4,4,figsize=(16,16))\n",
        "for i,ax in tqdm(zip(range(16),axes.flat)):\n",
        "    temp_df = df[df['filename']==folder_images[i]].reset_index(drop=True)\n",
        "    temp_img = cv2.imread(path+folder_images[i])\n",
        "    temp_img = cv2.cvtColor(temp_img, cv2.COLOR_BGR2RGB)\n",
        "    for j in range(len(temp_df)):\n",
        "        rect = cv2.rectangle(temp_img,(temp_df.loc[j,'xmin'],temp_df.loc[j,'ymin']),(temp_df.loc[j,'xmax'],temp_df.loc[j,'ymax']),(255,0,0),2,cv2.LINE_AA)\n",
        "        rect_text = cv2.putText(rect,temp_df.loc[j,'class'],(temp_df.loc[j,'xmin'],temp_df.loc[j,'ymin']-8), cv2.FONT_HERSHEY_SIMPLEX,1, (255,255,0), 2, cv2.LINE_AA)\n",
        "    ax.imshow(rect_text)\n",
        "    plt.axis('off')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4hEIk6AVZtN"
      },
      "source": [
        "# Selective search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuR0bICpVZtP"
      },
      "outputs": [],
      "source": [
        "cv2.setUseOptimized(True);\n",
        "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytb7JKoMVZtQ"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(path+folder_images[45])\n",
        "ss.setBaseImage(img)\n",
        "ss.switchToSelectiveSearchFast()\n",
        "rects = ss.process()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7DR1iDrVZtQ"
      },
      "outputs": [],
      "source": [
        "sel_rects = rects[:1200]\n",
        "imOut = img.copy()\n",
        "for i, rect in (enumerate(sel_rects)):\n",
        "    x, y, w, h = rect\n",
        "    cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(imOut)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0h5znZuDVZtS"
      },
      "source": [
        "# Define some function\n",
        "Now we use our defined function for getting region proposal from images. In this function we just have to add image path and dataframe which contain true label of that image in ['filename','width','height','class','xmin','ymin','xmax','ymax'] this format."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DKpeg8DVZtT"
      },
      "source": [
        "# Check for one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wg6JAy9WVZtU"
      },
      "outputs": [],
      "source": [
        "from region_proposals import iou_filter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "RxMbBGw6_wdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Parameter values for grid search\n",
        "thresh_values = [0.5]"
      ],
      "metadata": {
        "id": "CkuTYsYh_3Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = YourModel()  # Replace with your actual model instantiation\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "# iou_loss = IoULoss()"
      ],
      "metadata": {
        "id": "gXopZx8gABfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuHocTHTVZtU"
      },
      "outputs": [],
      "source": [
        "ss,neg =iou_filter(path+folder_images[950],df,thresh=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6tU7JczVZtV"
      },
      "source": [
        "Now visualize only region which have IoU greater than 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB2J0cA9VZtW"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(path+folder_images[950])\n",
        "for i, rect in (enumerate(ss)):\n",
        "    x, y, w, h = rect[0]\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GI7d2wb2VZtX"
      },
      "outputs": [],
      "source": [
        "len(ss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZ2s0JDNVZta"
      },
      "outputs": [],
      "source": [
        "len(neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avs6XWK9VZtc"
      },
      "source": [
        "Regions which has iou < 0.2 Which will use for background class training in CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6N5AOzEGVZtc"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(path+folder_images[95])\n",
        "for i, rect in (enumerate(neg)):\n",
        "    x, y, w, h = rect\n",
        "\n",
        "    cv2.rectangle(img, (x, y), (x+w, y+h), (0, 255, 0), 2, cv2.LINE_AA)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rua6enZXVZtd"
      },
      "source": [
        "# Saving all region proposal of all images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBt8pjb_VZte"
      },
      "source": [
        "This will take arround 1.5 hour to process so if you don't want to proccess it all ready in DATA directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN-bojMYVZte"
      },
      "outputs": [],
      "source": [
        "# Store grid search results\n",
        "grid_search_results = {}\n",
        "\n",
        "for thresh_value in thresh_values:\n",
        "    train_data = {}\n",
        "    test_data = {}\n",
        "\n",
        "    for i,img in tqdm(enumerate(train_images)):\n",
        "      ss,neg =iou_filter(path + img , df , thresh=0.5)\n",
        "      train_data[img] = {'region_proposal':ss,'negative_example':neg}\n",
        "\n",
        "    for i, img in enumerate(test_images):\n",
        "        ss, neg = iou_filter(path + img, df, thresh=0.5)\n",
        "        test_data[img] = {'region_proposal': ss, 'negative_example': neg}\n",
        "\n",
        "    # Store the results for this threshold value\n",
        "    grid_search_results[thresh_value] = {'train_data': train_data, 'test_data': test_data}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Grid Search Results:\")\n",
        "for thresh_value, result in grid_search_results.items():\n",
        "    print(f\"Threshold: {thresh_value}, Train Data Length: {len(result['train_data'])}, Test Data Length: {len(result['test_data'])}\")"
      ],
      "metadata": {
        "id": "bKB97IkhCLnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the best hyperparameters based on your evaluation metric (replace with your logic)\n",
        "best_thresh_value = max(grid_search_results, key=lambda k: len(grid_search_results[k]['train_data']))"
      ],
      "metadata": {
        "id": "QGHZiu0kCNHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the best hyperparameters in further analysis or visualization\n",
        "best_train_data = grid_search_results[best_thresh_value]['train_data']\n",
        "best_test_data = grid_search_results[best_thresh_value]['test_data']"
      ],
      "metadata": {
        "id": "1Jw8oAauCRwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I7z1SslT_XIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "H9koNOLBCSXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNQoe0k6VZtf"
      },
      "outputs": [],
      "source": [
        "# for i,img in tqdm(enumerate(train_images)):\n",
        "#     ss,neg =iou_filter(path + img , df , thresh=0.5)\n",
        "#     train_data[img] = {'region_proposal':ss,'negative_example':neg}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sgNKZo4UVZtg"
      },
      "outputs": [],
      "source": [
        "# for i,img in tqdm(enumerate(test_images)):\n",
        "#     ss,neg =iou_filter(path + img , df , thresh=0.5)\n",
        "#     test_data[img] = {'region_proposal':ss,'negative_example':neg}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUwpSxtlVZti"
      },
      "outputs": [],
      "source": [
        "#converting numpy instantant into python datatype\n",
        "import json\n",
        "class MyEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        elif isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        else:\n",
        "            return super(MyEncoder, self).default(obj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59REqmr9VZtj"
      },
      "outputs": [],
      "source": [
        "with open('train.json','w+') as output_file:\n",
        "    json.dump(train_data,output_file,cls=MyEncoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8uOKCyaVZtj"
      },
      "outputs": [],
      "source": [
        "with open('test.json','w+') as output_file:\n",
        "    json.dump(test_data,output_file,cls=MyEncoder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fD_rkhucVZtk"
      },
      "source": [
        "checking our conversion is right or wrong"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRz438ebVZtk"
      },
      "outputs": [],
      "source": [
        "with open('train.json') as train:\n",
        "    train_json = json.load(train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v2ikgLTKVZtl"
      },
      "outputs": [],
      "source": [
        "with open('test.json') as test:\n",
        "    test_json = json.load(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x__uQTuQVZtl",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "train_json == train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QbqNQZwhVZtl"
      },
      "outputs": [],
      "source": [
        "test_json == test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4R833s6tExn"
      },
      "source": [
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gzz3bsYtINX"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Generate a random binary classification dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, random_state=42)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train a logistic regression model\n",
        "model = LogisticRegression(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Form a confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Calculate precision, accuracy, and recall\n",
        "precision = precision_score(y_test, y_pred)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Recall:\", recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGM9F-HKwh59"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['crop', 'weed']\n",
        "fig, ax = plt.subplots()\n",
        "im = ax.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "ax.set(xticks=np.arange(cm.shape[1]),\n",
        "       yticks=np.arange(cm.shape[0]),\n",
        "       xticklabels=labels, yticklabels=labels,\n",
        "       xlabel='Predicted label',\n",
        "       ylabel='True label')\n",
        "\n",
        "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
        "         rotation_mode=\"anchor\")\n",
        "\n",
        "for i in range(cm.shape[0]):\n",
        "    for j in range(cm.shape[1]):\n",
        "        ax.text(j, i, format(cm[i, j], 'd'),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if cm[i, j] > cm.max() / 2. else \"black\")\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSKHiYGLwiPe"
      },
      "outputs": [],
      "source": [
        "# Calculate IoU for each class\n",
        "num_classes = len(labels)\n",
        "iou = np.zeros(num_classes)\n",
        "for c in range(num_classes):\n",
        "    intersection = cm[c,c]\n",
        "    union = (cm[c,:].sum() + cm[:,c].sum()) - intersection\n",
        "    iou[c] = intersection / union\n",
        "\n",
        "# Print IoU for each class\n",
        "for c in range(num_classes):\n",
        "    print(f\"IoU for {labels[c]}: {iou[c]:.2f}\")\n",
        "\n",
        "# Plot IoU as a bar graph\n",
        "plt.bar(range(num_classes), iou)\n",
        "plt.xticks(range(num_classes), labels, rotation=90)\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('IoU')\n",
        "plt.ylim((0,1))\n",
        "plt.title('Intersection over Union (IoU)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# WIOU (Weighted IoU)\n",
        "wiou = iou.mean()\n",
        "\n",
        "# EIOU (Element-wise IoU)\n",
        "eiou = iou / cm.sum(axis=1)\n",
        "\n",
        "# CIOU (Class-wise IoU)\n",
        "ciou = iou / num_classes\n",
        "\n",
        "# Print results\n",
        "print(\"Weighted IoU (WIOU):\", wiou)\n",
        "print(\"Element-wise IoU (EIOU):\", eiou)\n",
        "print(\"Class-wise IoU (CIOU):\", ciou)\n"
      ],
      "metadata": {
        "id": "h4_NK7c0He3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EIOU Loss (Element-wise IoU Loss)\n",
        "eiou_loss = 1 - eiou\n",
        "\n",
        "# CIOU Loss (Class-wise IoU Loss)\n",
        "ciou_loss = 1 - ciou\n",
        "\n",
        "# SIOU Loss (Sum of IoU Loss)\n",
        "siou_loss = eiou_loss.sum()\n",
        "\n",
        "# WIOU V3 Loss (Weighted IoU V3 Loss)\n",
        "wiou_v3_loss = wiou - 1 / num_classes * ciou_loss\n",
        "\n",
        "# Print results\n",
        "print(\"Element-wise IoU Loss (EIOU Loss):\", eiou_loss)\n",
        "print(\"Class-wise IoU Loss (CIOU Loss):\", ciou_loss)\n",
        "print(\"Sum of IoU Loss (SIOU Loss):\", siou_loss)\n",
        "print(\"Weighted IoU V3 Loss (WIOU V3 Loss):\", wiou_v3_loss)\n"
      ],
      "metadata": {
        "id": "7j-xVxuYMVBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Bayesian Optimization"
      ],
      "metadata": {
        "id": "yzax-Un-9QFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install thop\n"
      ],
      "metadata": {
        "id": "sXbq8ZECMYeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch"
      ],
      "metadata": {
        "id": "xGIAE3HRMhrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from thop import profile\n",
        "import torch\n",
        "# Assume model is your PyTorch model\n",
        "input_tensor = torch.randn(1, 3, 224, 224)\n",
        "flops, params = profile(model, inputs=(input_tensor,))\n",
        "print(\"FLOPS:\", flops)\n"
      ],
      "metadata": {
        "id": "tBUHVEJ3McP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "# Assuming rcnn_model is your RCNN model\n",
        "batch_size = 16  # Adjust as needed\n",
        "input_tensor = torch.randn(batch_size, 3, 224, 224)  # Adjust input size accordingly\n",
        "\n",
        "# Measure time for inference\n",
        "start_time = time.time()\n",
        "for _ in range(100):  # Adjust the number of iterations\n",
        "    ss(input_tensor)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calculate FPS\n",
        "fps = 100 / (end_time - start_time)\n",
        "print(\"Frames per Second (FPS):\", fps)\n"
      ],
      "metadata": {
        "id": "RvJUhi-pMeha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0t_2vAZSNNaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from skopt import BayesSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the RCNN hyperparameter search space\n",
        "hyperparameter_space = {\n",
        "    'learning_rate': (0.001, 0.01),\n",
        "    'batch_size': (32, 128),\n",
        "    'num_layers': (2, 5),\n",
        "    # Add more hyperparameters as needed\n",
        "}\n",
        "def fitness_function(hyperparameters):\n",
        "    # Initialize and train the RCNN model with the given hyperparameters\n",
        "    baye_model = model(**hyperparameters)  # Instantiate your RCNN model with the hyperparameters\n",
        "    baye_model.fit(train_images, **hyperparameters)  # Train the model on the training images\n",
        "\n",
        "    # Evaluate the trained model on the validation set\n",
        "    y_pred = baye_model.predict(test_images)\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "\n",
        "    return accuracy\n",
        "\n",
        "bayes_optimizer = BayesSearchCV(\n",
        "    estimator=None,\n",
        "    search_spaces=hyperparameter_space,\n",
        "    scoring='accuracy',\n",
        "    n_iter=50,\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Run the Bayesian optimization\n",
        "bayes_optimizer.fit(X=None, y=None, callback=None, fit_params=None)\n",
        "\n",
        "# Get the best hyperparameters found by Bayesian optimization\n",
        "best_hyperparameters = bayes_optimizer.best_params_\n",
        "\n",
        "# Train the RCNN model using the best hyperparameters\n",
        "best_model = RCNN(**best_hyperparameters)\n",
        "best_model.fit(train_images, **best_hyperparameters)  # Train the model on the entire training set"
      ],
      "metadata": {
        "id": "Sb4fhpbhcimR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Crow search"
      ],
      "metadata": {
        "id": "_1y9gDZD0zHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model(\"my_model.h5\")\n"
      ],
      "metadata": {
        "id": "p-e7rfLH0x3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from cso import CrowSearchOptimizer  # Import CSO implementation (you may need to install this library)"
      ],
      "metadata": {
        "id": "9A_ggN2L06KM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the RCNN hyperparameter search space\n",
        "hyperparameter_space = {\n",
        "    'learning_rate': (0.001, 0.01),\n",
        "    'batch_size': (32, 128),\n",
        "    'num_layers': (2, 5),\n",
        "    # Add more hyperparameters as needed\n",
        "}\n",
        "\n",
        "def fitness_function(hyperparameters):\n",
        "    crow_model = model(**hyperparameters)\n",
        "    crow_model.fit(train_images, **hyperparameters)\n",
        "\n",
        "    y_pred = crow_model.predict(test_images)\n",
        "    accuracy = accuracy_score(test_labels, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "6wbdFOnm9pF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the CSO optimizer with the defined search space and fitness function\n",
        "cso_optimizer = CrowSearchOptimizer(\n",
        "    search_space=hyperparameter_space,\n",
        "    fitness_function=fitness_function,\n",
        "    num_population=20,  # Number of crows in the population\n",
        "    max_iter=100,       # Maximum number of iterations\n",
        "    verbose=True        # Enable verbose mode for debugging\n",
        ")\n",
        "\n",
        "# Run the CSO optimizer\n",
        "best_hyperparameters = cso_optimizer.optimize()"
      ],
      "metadata": {
        "id": "z07rjbzt92-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = model(**best_hyperparameters)\n",
        "best_model.fit(train_images, **best_hyperparameters)"
      ],
      "metadata": {
        "id": "Ca3ZNz6s97A7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NsxoDZJS9rQ0"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}